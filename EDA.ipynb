{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "# Auxiliary classes:\n",
    "from dataframeinfo import DataFrameInfo\n",
    "from dataframetransform import DataFrameTransform\n",
    "from datatransform import DataTransform\n",
    "from plotter import Plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data frame by reading csv file generated in dbutils.\n",
    "df = pd.read_csv('loan_payments_versions/loan_payments.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an instance of each auxiliary class.\n",
    "data = DataTransform()\n",
    "info = DataFrameInfo()\n",
    "plotter = Plotter()\n",
    "transform = DataFrameTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Formatting\n",
    "#By looking at the data some of the columns do not contain data in the correct format, using the DataTransform class these can be corrected. The main incorrect formats identified are:\n",
    "\n",
    "#'verification_status' column contains the strings 'Source Verified' and 'Verified' which have the same meaning.\n",
    "#columns with dates are in string format.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data.replace_string_text(df, 'verification_status', 'Source ', '') # Replace the word 'source' with '' in the verification status column.\n",
    "date_columns = ['issue_date', 'earliest_credit_line', 'last_payment_date', 'next_payment_date', 'last_credit_pull_date'] # Specifies the columns which need to convert a string to a date.\n",
    "for column in date_columns:\n",
    "    data.convert_string_to_date(df, column) # Applies the convert_string_to_date() method to each column in the date_columns l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null imputation\n",
    "null_columns = info.get_null_columns(df)\n",
    "for column in null_columns: # For each column that contains null values.\n",
    "    print(f'{column}: {round(info.null_percentage(df, column),2)} %') # Print the column and the percentage of null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = info.identify_conditional_null_columns(df, '>', 10) # Calls method to input the columns that contain '>' '10' % null values into a list.\n",
    "transform.remove_null_columns(df, columns_to_remove) # Removes all columns in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_with_rows_to_remove = info.identify_conditional_null_columns(df, '<', 1) # Calls method to input the columns that contain '<' '1' % null values into a list.\n",
    "transform.remove_null_rows(df, columns_with_rows_to_remove) # Removes all rows within the list of columns that contain null values.\n",
    "\n",
    "plotter.missing_matrix(df) # Visualise remaining missing data."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
